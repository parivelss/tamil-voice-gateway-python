#!/usr/bin/env python3
"""
Test script for improved conversation flow - no repetitive questions, progressive investigation
"""

import asyncio
import sys
import os

# Add the app directory to the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.adapters.gemini_llm import GeminiLLMAdapter

async def test_progressive_investigation():
    """Test progressive questioning without repetition"""
    print("ğŸ” Testing Progressive Investigation Flow")
    print("=" * 60)
    
    # Initialize Gemini LLM adapter
    gemini_llm = GeminiLLMAdapter()
    
    # Simulate the exact conversation from the user's example
    conversation_flow = [
        {
            "patient": "à®à®©à®•à¯à®•à¯ à®•à®¾à®²à¯ à®°à¯Šà®®à¯à®ª à®µà®²à®¿à®•à¯à®•à¯à®¤à¯ à®à®©à¯à®©à®¤à®¾à®©à¯ à®ªà®£à¯à®±à®¤à¯",
            "expected": "Should greet and ask about onset/severity"
        },
        {
            "patient": "à®à®©à®•à¯à®•à¯à®®à¯ à®®à¯à®¨à¯à®¤à®¾à®¨à¯‡à®¤à¯à®¤à®¿à®²à¯ à®‡à®°à¯à®¨à¯à®¤à¯ à®•à®¾à®²à¯ à®µà®²à®¿ à®‡à®©à¯à®Ÿà®°à¯à®šà®¿à®Ÿà¯à®Ÿà®¿ à®’à®°à¯ 9/10 à®ªà®¯à®™à¯à®•à®°à®®à®¾ à®‡à®°à¯à®•à¯à®•à¯à®¤à¯ à®ªà¯Šà®±à¯à®•à¯à®•à®µà¯‡ à®®à¯à®Ÿà®¿à®¯à®²",
            "expected": "Should NOT repeat onset/severity questions, ask about location/triggers"
        },
        {
            "patient": "Calf muscle-à®² à®¤à®¾à®©à¯ à®µà®²à®¿, walking à®ªà®£à¯à®±à®ªà¯à®ªà¯‹ à®…à®¤à®¿à®•à®®à®¾ à®µà®²à®¿à®•à¯à®•à¯à®¤à¯",
            "expected": "Should ask about associated symptoms or treatments tried"
        },
        {
            "patient": "Swelling à®•à¯Šà®à¯à®šà®®à¯ à®‡à®°à¯à®•à¯à®•à¯, medicine à®à®¤à¯à®µà¯à®®à¯ à®šà®¾à®ªà¯à®ªà®¿à®Ÿà®²",
            "expected": "Should provide summary and doctor referral"
        }
    ]
    
    for i, exchange in enumerate(conversation_flow, 1):
        print(f"\n{i}. Patient: {exchange['patient']}")
        print(f"   Expected: {exchange['expected']}")
        
        try:
            # Check if this should trigger summary
            should_summarize = i >= 4  # After 4th exchange
            
            response = await gemini_llm.chat(
                user_message=exchange['patient'],
                language="ta",
                should_summarize=should_summarize
            )
            
            print(f"   Doctor: {response}")
            
            # Check for issues
            issues = []
            
            # Check for repetitive vanakkam
            if i > 1 and "à®µà®£à®•à¯à®•à®®à¯" in response:
                issues.append("âŒ Repetitive vanakkam greeting")
            elif i == 1 and "à®µà®£à®•à¯à®•à®®à¯" not in response:
                issues.append("âŒ Missing initial greeting")
            else:
                issues.append("âœ… Appropriate greeting usage")
            
            # Check for repetitive questions
            if i == 2:  # Second response
                if "à®à®ªà¯à®ªà¯‹" in response or "start" in response:
                    issues.append("âŒ Repeating onset question")
                elif "à®à®µà¯à®µà®³à®µà¯" in response and "severe" in response:
                    issues.append("âŒ Repeating severity question")
                else:
                    issues.append("âœ… No repetitive questions")
            
            # Check for progressive questioning
            question_count = response.count('?')
            if question_count <= 2:
                issues.append(f"âœ… Question limit respected: {question_count}")
            else:
                issues.append(f"âŒ Too many questions: {question_count}")
            
            # Check for summary trigger
            if should_summarize and "senior doctor" in response:
                issues.append("âœ… Summary and referral triggered")
            elif should_summarize:
                issues.append("âŒ Summary not triggered when expected")
            
            for issue in issues:
                print(f"   {issue}")
                
        except Exception as e:
            print(f"   âŒ Error: {str(e)}")

async def test_memory_retention():
    """Test that AI remembers what patient has already told"""
    print(f"\nğŸ§  Testing Memory Retention")
    print("=" * 40)
    
    gemini_llm = GeminiLLMAdapter()
    
    # First exchange - establish baseline info
    response1 = await gemini_llm.chat("I have headache for 3 days, very severe", "en")
    print(f"1. Patient: I have headache for 3 days, very severe")
    print(f"   Doctor: {response1}")
    
    # Second exchange - should NOT ask about duration or severity again
    response2 = await gemini_llm.chat("It's getting worse", "en")
    print(f"\n2. Patient: It's getting worse")
    print(f"   Doctor: {response2}")
    
    # Check if doctor remembered previous info
    memory_check = []
    if "à®à®ªà¯à®ªà¯‹" not in response2 and "start" not in response2:
        memory_check.append("âœ… Didn't repeat onset question")
    else:
        memory_check.append("âŒ Repeated onset question")
        
    if "à®à®µà¯à®µà®³à®µà¯" not in response2 and "severe" not in response2:
        memory_check.append("âœ… Didn't repeat severity question")
    else:
        memory_check.append("âŒ Repeated severity question")
    
    for check in memory_check:
        print(f"   {check}")

if __name__ == "__main__":
    asyncio.run(test_progressive_investigation())
    asyncio.run(test_memory_retention())
